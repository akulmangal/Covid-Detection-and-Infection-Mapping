{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>MODELS(COVID PROJECT)</h1>\n<ul>\n    <li>This Notebook contains the formation of models on both the datasets</li>\n    <li>The Datasets have undergone through various image processing techniques done in Lung Segmentation with Documentation.ipynb</li>","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:24:50.095844Z","iopub.execute_input":"2021-12-21T08:24:50.096135Z","iopub.status.idle":"2021-12-21T08:24:50.105453Z","shell.execute_reply.started":"2021-12-21T08:24:50.096103Z","shell.execute_reply":"2021-12-21T08:24:50.104246Z"}}},{"cell_type":"code","source":"import os\nimport cv2\nimport keras\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import load_model  \n#from keras.utils import plot_model\nfrom keras import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Softmax,Activation,Dense,Dropout\nfrom keras.callbacks import Callback,ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,auc\n#from skimage.transform import rescale, resize\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nimport pickle\nfrom skimage import measure\nfrom skimage import morphology\nfrom skimage.transform import resize\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:08:53.567206Z","iopub.execute_input":"2021-12-21T09:08:53.567485Z","iopub.status.idle":"2021-12-21T09:08:53.577128Z","shell.execute_reply.started":"2021-12-21T09:08:53.567455Z","shell.execute_reply":"2021-12-21T09:08:53.575905Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras.models import load_model \nfrom keras.utils.vis_utils import plot_model\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:20:50.386864Z","iopub.execute_input":"2021-12-21T08:20:50.387150Z","iopub.status.idle":"2021-12-21T08:20:50.395213Z","shell.execute_reply.started":"2021-12-21T08:20:50.387119Z","shell.execute_reply":"2021-12-21T08:20:50.394054Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex2 import *\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import optimizers, losses, activations, models\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import EfficientNetB1\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications.densenet  import DenseNet169\nfrom keras.layers import LSTM\nfrom keras.layers import TimeDistributed","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:21:13.188827Z","iopub.execute_input":"2021-12-21T08:21:13.189606Z","iopub.status.idle":"2021-12-21T08:21:13.621472Z","shell.execute_reply.started":"2021-12-21T08:21:13.189572Z","shell.execute_reply":"2021-12-21T08:21:13.620595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport scipy.ndimage\nfrom skimage import morphology\nfrom skimage import measure\nfrom skimage.transform import resize\nfrom sklearn.cluster import KMeans\nimport cv2\nimport glob","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:21:22.083903Z","iopub.execute_input":"2021-12-21T08:21:22.084178Z","iopub.status.idle":"2021-12-21T08:21:22.090656Z","shell.execute_reply.started":"2021-12-21T08:21:22.084148Z","shell.execute_reply":"2021-12-21T08:21:22.089557Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"<h3>Image Data Generator</h3>\n<ol>\n    <li>Used for Loading the datasets</li>\n    <li>Perform Techniques like Pixel centering, Pixel Normalization and Pixel Standardization</li>\n    <li>Validation Split is only used in the first dataset. It is a 70-30 split</li>\n</ol>","metadata":{}},{"cell_type":"markdown","source":"<h4>Dataset 1</h4>","metadata":{}},{"cell_type":"code","source":"covid_dir='../input/covid-project/Image Dataset 2/IMAGES_NoHist13000'\nSIZE_X=SIZE_Y=224\nBATCH_SIZE = 128\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen=ImageDataGenerator(rescale=1.0/255.0,\n                           featurewise_center=True,\n                           featurewise_std_normalization=True,\n                           validation_split = 0.3)\ntraining=datagen.flow_from_directory(covid_dir,\n                                  class_mode = \"categorical\",\n                                  target_size = (SIZE_X,SIZE_Y),\n                                  color_mode=\"rgb\",\n                                  batch_size = 128, \n                                  shuffle = False,\n                                  subset='training',\n                                  seed = 42)\n\nvalidation=datagen.flow_from_directory(covid_dir,\n                                    class_mode = \"categorical\",\n                                    target_size = (SIZE_X,SIZE_Y),\n                                    color_mode=\"rgb\",\n                                    batch_size = 128, \n                                    shuffle = False,\n                                    subset='validation',\n                                    seed = 42)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:21:44.467935Z","iopub.execute_input":"2021-12-21T08:21:44.468212Z","iopub.status.idle":"2021-12-21T08:21:49.937801Z","shell.execute_reply.started":"2021-12-21T08:21:44.468182Z","shell.execute_reply":"2021-12-21T08:21:49.936843Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<h4>Dataset 2</h4>","metadata":{}},{"cell_type":"code","source":"covid_dir='../input/covid-project/Image Dataset 2/Images_NoHist2000'\nSIZE_X=SIZE_Y=224\nBATCH_SIZE = 128\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen2=ImageDataGenerator(rescale=1.0/255.0,\n                           featurewise_center=True,\n                           featurewise_std_normalization=True)\ntesting=datagen2.flow_from_directory(covid_dir,\n                                  class_mode = \"categorical\",\n                                  target_size = (SIZE_X,SIZE_Y),\n                                  color_mode=\"rgb\",\n                                  batch_size = 128, \n                                  shuffle = False,\n                                  #subset='training',\n                                  seed = 42)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:22:55.896181Z","iopub.execute_input":"2021-12-21T08:22:55.896523Z","iopub.status.idle":"2021-12-21T08:22:56.685310Z","shell.execute_reply.started":"2021-12-21T08:22:55.896476Z","shell.execute_reply":"2021-12-21T08:22:56.684258Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<h3>Models</h3><br>\n<ol>\n    <li>Weights Are Loaded From Keras Library</li>\n    <li>All the models undergo Transfer Learning and Fine tuning</li>\n    <li>The Head of The model is changed according to the datasets</li>\n    <li>The best weights of the model are stored</li>\n    <li>The model is trained and Validated on the first dataset and using the weights the model has learnt from the first dataset,it tests its results on the second dataset</li>\n    <li>Confusion Matrix,Classification report and Roc curves are used to test and Compare the accuracies of the models</li>\n</ol>","metadata":{}},{"cell_type":"markdown","source":"<h4>VGG16</h4>","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape,n_classes,optimizer='adam',fine_tune=0):\n    conv_base = VGG16(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n    \n    model = Sequential()\n    model.add(conv_base)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(2, activation='softmax'))\n    \n    model.compile(optimizer = 'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:36:36.117934Z","iopub.execute_input":"2021-12-21T08:36:36.118292Z","iopub.status.idle":"2021-12-21T08:36:36.127966Z","shell.execute_reply.started":"2021-12-21T08:36:36.118260Z","shell.execute_reply":"2021-12-21T08:36:36.126801Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"input_shape=(224,224,3)\noptim_1 = Adam(lr=0.0001)\nn_classes=2\n\nn_steps=training.samples//128\nn_val_steps=validation.samples//128\nn_epochs=10\n\nvggmodel=create_model(input_shape,n_classes,optim_1,fine_tune=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:36:57.114932Z","iopub.execute_input":"2021-12-21T08:36:57.115258Z","iopub.status.idle":"2021-12-21T08:37:01.114242Z","shell.execute_reply.started":"2021-12-21T08:36:57.115223Z","shell.execute_reply":"2021-12-21T08:37:01.113136Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"vggmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:37:08.973188Z","iopub.execute_input":"2021-12-21T08:37:08.973986Z","iopub.status.idle":"2021-12-21T08:37:08.990339Z","shell.execute_reply.started":"2021-12-21T08:37:08.973953Z","shell.execute_reply":"2021-12-21T08:37:08.988424Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"vgg_checkpoint = ModelCheckpoint(filepath='cnn+vggmodel(revised2)_new.weights.best.hdf5',\n                                  save_best_only=True,\n                                  verbose=1)\n\n# EarlyStopping\nearly_stop = EarlyStopping(monitor='val_accuracy',\n                           patience=7,\n                           restore_best_weights=True,\n                           mode='max')\nvgg_history = vggmodel.fit(training,\n                           batch_size=BATCH_SIZE,\n                           epochs=n_epochs,\n                           validation_data=(validation),\n                           steps_per_epoch=n_steps,\n                           validation_steps=n_val_steps,\n                           callbacks=[vgg_checkpoint, early_stop],\n                           verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T20:12:30.456685Z","iopub.execute_input":"2021-12-13T20:12:30.456962Z","iopub.status.idle":"2021-12-13T20:13:06.700152Z","shell.execute_reply.started":"2021-12-13T20:12:30.456935Z","shell.execute_reply":"2021-12-13T20:13:06.698722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnvggmodel(revised)_new.weights.best (4).hdf5') # initialize the best trained weights\ntrue_classes = testing.classes\nvgg_preds = vggmodel.predict(testing)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = testing.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"VGG16 Accuracy Dataset 2: {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:40:26.348622Z","iopub.execute_input":"2021-12-21T08:40:26.349068Z","iopub.status.idle":"2021-12-21T08:40:37.929552Z","shell.execute_reply.started":"2021-12-21T08:40:26.349032Z","shell.execute_reply":"2021-12-21T08:40:37.928483Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnvggmodel(revised)_new.weights.best (4).hdf5') # initialize the best trained weights\ntrue_classes2 = training.classes\nvgg_preds = vggmodel.predict(training)\nvgg_pred_classes2 = np.argmax(vgg_preds, axis=1)\nclass_indices =training.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes2,vgg_pred_classes2, target_names=target))\nvgg_acc = accuracy_score(true_classes2, vgg_pred_classes2)*100\nprint(\"VGG16 Accuracy Dataset1(Training) : {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:42:05.841148Z","iopub.execute_input":"2021-12-21T08:42:05.841494Z","iopub.status.idle":"2021-12-21T08:43:08.714553Z","shell.execute_reply.started":"2021-12-21T08:42:05.841463Z","shell.execute_reply":"2021-12-21T08:43:08.713541Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnvggmodel(revised)_new.weights.best (4).hdf5') # initialize the best trained weights\ntrue_classes = validation.classes\nvgg_preds = vggmodel.predict(validation)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = validation.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"VGG16 Accuracy Dataset1(Validation) : {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:44:06.220161Z","iopub.execute_input":"2021-12-21T08:44:06.220467Z","iopub.status.idle":"2021-12-21T08:44:42.300561Z","shell.execute_reply.started":"2021-12-21T08:44:06.220435Z","shell.execute_reply":"2021-12-21T08:44:42.299441Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<h5>Confusion Matrix</h5>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(training.classes, np.argmax(vggmodel.predict(training), axis=1))\ncm2 = confusion_matrix(validation.classes, np.argmax(vggmodel.predict(validation), axis=1))\ncm1 = cm+cm2\ncm3 = confusion_matrix(testing.classes, np.argmax(vggmodel.predict(testing), axis=1))\ngroup_names = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm1.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm1.flatten()/np.sum(cm1)]\nLabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nLabels = np.asarray(Labels).reshape(2,2)\ngroup_names2 = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts2 = [\"{0:0.0f}\".format(value) for value in cm2.flatten()]\ngroup_percentages2 = [\"{0:.2%}\".format(value) for value in cm2.flatten()/np.sum(cm2)]\nLabels2 = [f\"{v11}\\n{v22}\\n{v33}\" for v11, v22, v33 in zip(group_names2,group_counts2,group_percentages2)]\nLabels2 = np.asarray(Labels2).reshape(2,2)\ngroup_names3 = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts3 = [\"{0:0.0f}\".format(value) for value in cm3.flatten()]\ngroup_percentages3 = [\"{0:.2%}\".format(value) for value in cm3.flatten()/np.sum(cm3)]\nLabels3 = [f\"{v111}\\n{v222}\\n{v333}\" for v111, v222, v333 in zip(group_names3,group_counts3,group_percentages3)]\nLabels3 = np.asarray(Labels3).reshape(2,2)\nfig,[ax1,ax2] = plt.subplots(nrows=1,ncols=2,figsize=(10,5),constrained_layout = True)\nsns.heatmap(cm1, annot=Labels, fmt='', cmap='Reds',ax=ax1)\nax1.set_xlabel('Predicted labels')\nax1.set_ylabel('True labels')\nax1.set_title(\"Dataset1\")\nax1.xaxis.set_ticklabels([target[0], target[1]]); ax1.yaxis.set_ticklabels([target[0], target[1]])\nsns.heatmap(cm3, annot=Labels3, fmt='', cmap='Blues',ax=ax2)\nax2.set_xlabel('Predicted labels')\nax2.set_ylabel('True labels')\nax2.set_title(\"Dataset2\")\nax2.xaxis.set_ticklabels([target[0], target[1]]); ax2.yaxis.set_ticklabels([target[0], target[1]])\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.7, \n                    hspace=0.7)\n#fig.suptitle(\"This Main Title is Nicely Formatted\", fontsize=16)\n#fig.suptitle('VGG16+CNN Results(Confusion Matrix)')\n#plt.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:46:07.780503Z","iopub.execute_input":"2021-12-21T08:46:07.781170Z","iopub.status.idle":"2021-12-21T08:47:14.886621Z","shell.execute_reply.started":"2021-12-21T08:46:07.781124Z","shell.execute_reply":"2021-12-21T08:47:14.885550Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"<h5>ROC Curve</h5>","metadata":{}},{"cell_type":"code","source":"test_labels = training.classes\nresults = np.argmax(vggmodel.predict(training), axis=1)\ntest_labels2 = validation.classes\nresults2 = np.argmax(vggmodel.predict(validation), axis=1)\ntest_labels3 = testing.classes\nresults3 = np.argmax(vggmodel.predict(testing), axis=1)\nfrom scipy import interp\nfrom itertools import cycle\nfrom sklearn.metrics import roc_curve\nlw = 2\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(1):\n    fpr[i], tpr[i], _ = roc_curve(results,test_labels)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\nfor i in range(1):\n    fpr2[i], tpr2[i], _ = roc_curve(results2,test_labels2)\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n    \nfpr3 = dict()\ntpr3 = dict()\nroc_auc3 = dict()\nfor i in range(1):\n    fpr3[i], tpr3[i], _ = roc_curve(results3,test_labels3)\n    roc_auc3[i] = auc(fpr3[i], tpr3[i])\n\n\ncolors = cycle(['red', 'red'])\nfor i, color in zip(range(1), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='D1:Training (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\ncolors2 = cycle(['blue', 'blue'])\nfor i, color in zip(range(1), colors2):\n    plt.plot(fpr2[i], tpr2[i], color=color, lw=lw,\n             label='D1:Validation (area = {1:0.2f})'\n             ''.format(i, roc_auc2[i]))\ncolors3 = cycle(['orange', 'orange'])\nfor i, color in zip(range(1), colors3):\n    plt.plot(fpr3[i], tpr3[i], color=color, lw=lw,\n             label='D2 (area = {1:0.2f})'\n             ''.format(i, roc_auc3[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve: VGG16')\nplt.legend(bbox_to_anchor=(1.8, 1.0), loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:47:31.507741Z","iopub.execute_input":"2021-12-21T08:47:31.508082Z","iopub.status.idle":"2021-12-21T08:48:25.394248Z","shell.execute_reply.started":"2021-12-21T08:47:31.508050Z","shell.execute_reply":"2021-12-21T08:48:25.393320Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<h4>VGG19</h4>","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape,n_classes,optimizer='adam',fine_tune=0):\n    conv_base = VGG19(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n    \n    model = Sequential()\n    model.add(conv_base)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(2, activation='softmax'))\n    \n    model.compile(optimizer = 'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:49:46.546984Z","iopub.execute_input":"2021-12-21T08:49:46.547315Z","iopub.status.idle":"2021-12-21T08:49:46.556237Z","shell.execute_reply.started":"2021-12-21T08:49:46.547283Z","shell.execute_reply":"2021-12-21T08:49:46.555265Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_shape=(224,224,3)\noptim_1 = Adam(lr=0.0001)\nn_classes=2\n\nn_steps=training.samples//128\nn_val_steps=validation.samples//128\nn_epochs=10\n\nvggmodel19=create_model(input_shape,n_classes,optim_1,fine_tune=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:49:58.651143Z","iopub.execute_input":"2021-12-21T08:49:58.651489Z","iopub.status.idle":"2021-12-21T08:50:01.917539Z","shell.execute_reply.started":"2021-12-21T08:49:58.651457Z","shell.execute_reply":"2021-12-21T08:50:01.916561Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"vggmodel19.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:50:13.830716Z","iopub.execute_input":"2021-12-21T08:50:13.831112Z","iopub.status.idle":"2021-12-21T08:50:13.846977Z","shell.execute_reply.started":"2021-12-21T08:50:13.831074Z","shell.execute_reply":"2021-12-21T08:50:13.845821Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"vgg_checkpoint = ModelCheckpoint(filepath='cnn+vggmodel19(nnew).weights.best.hdf5',\n                                  save_best_only=True,\n                                  verbose=1)\n\n# EarlyStopping\nearly_stop = EarlyStopping(monitor='val_accuracy',\n                           patience=5,\n                           restore_best_weights=True,\n                           mode='max')","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:17:41.372989Z","iopub.execute_input":"2021-12-09T15:17:41.373357Z","iopub.status.idle":"2021-12-09T15:17:41.378887Z","shell.execute_reply.started":"2021-12-09T15:17:41.373328Z","shell.execute_reply":"2021-12-09T15:17:41.377723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19_history = vggmodel19.fit(training,\n                           batch_size=BATCH_SIZE,\n                           epochs=n_epochs,\n                           validation_data=(validation),\n                           steps_per_epoch=n_steps,\n                           validation_steps=n_val_steps,\n                           callbacks=[vgg_checkpoint, early_stop],\n                           verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T15:17:44.800708Z","iopub.execute_input":"2021-12-09T15:17:44.801026Z","iopub.status.idle":"2021-12-09T15:28:43.950181Z","shell.execute_reply.started":"2021-12-09T15:17:44.800994Z","shell.execute_reply":"2021-12-09T15:28:43.949299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel19.load_weights('../input/cnn-model/cnnvggmodel19(nnew).weights.best.hdf5') # initialize the best trained weights\ntrue_classes = testing.classes\nvgg_preds = vggmodel19.predict(testing)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = testing.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Vgg19 Accuracy on Dataset2: {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:51:38.335508Z","iopub.execute_input":"2021-12-21T08:51:38.335839Z","iopub.status.idle":"2021-12-21T08:51:52.453708Z","shell.execute_reply.started":"2021-12-21T08:51:38.335788Z","shell.execute_reply":"2021-12-21T08:51:52.452660Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel19.load_weights('../input/cnn-model/cnnvggmodel19(nnew).weights.best.hdf5') # initialize the best trained weights\ntrue_classes = training.classes\nvgg_preds = vggmodel19.predict(training)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = training.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Vgg19 Accuracy on Dataset1(Training): {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:52:53.556482Z","iopub.execute_input":"2021-12-21T08:52:53.556756Z","iopub.status.idle":"2021-12-21T08:53:33.568407Z","shell.execute_reply.started":"2021-12-21T08:52:53.556726Z","shell.execute_reply":"2021-12-21T08:53:33.567368Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel19.load_weights('../input/cnn-model/cnnvggmodel19(nnew).weights.best.hdf5') # initialize the best trained weights\ntrue_classes = validation.classes\nvgg_preds = vggmodel19.predict(validation)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = validation.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Vgg19 Accuracy on Dataset1(Validation): {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:54:09.675084Z","iopub.execute_input":"2021-12-21T08:54:09.675360Z","iopub.status.idle":"2021-12-21T08:54:28.844018Z","shell.execute_reply.started":"2021-12-21T08:54:09.675330Z","shell.execute_reply":"2021-12-21T08:54:28.843036Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"<h5>Confusion Matrix</h5>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(training.classes, np.argmax(vggmodel19.predict(training), axis=1))\ncm2 = confusion_matrix(validation.classes, np.argmax(vggmodel19.predict(validation), axis=1))\ncm1 = cm+cm2\ncm3 = confusion_matrix(testing.classes, np.argmax(vggmodel19.predict(testing), axis=1))\ngroup_names = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm1.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm1.flatten()/np.sum(cm1)]\nLabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nLabels = np.asarray(Labels).reshape(2,2)\ngroup_names2 = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts2 = [\"{0:0.0f}\".format(value) for value in cm2.flatten()]\ngroup_percentages2 = [\"{0:.2%}\".format(value) for value in cm2.flatten()/np.sum(cm2)]\nLabels2 = [f\"{v11}\\n{v22}\\n{v33}\" for v11, v22, v33 in zip(group_names2,group_counts2,group_percentages2)]\nLabels2 = np.asarray(Labels2).reshape(2,2)\ngroup_names3 = [\"TN\",\"FP\",\"FN\",\"TP\"]\ngroup_counts3 = [\"{0:0.0f}\".format(value) for value in cm3.flatten()]\ngroup_percentages3 = [\"{0:.2%}\".format(value) for value in cm3.flatten()/np.sum(cm3)]\nLabels3 = [f\"{v111}\\n{v222}\\n{v333}\" for v111, v222, v333 in zip(group_names3,group_counts3,group_percentages3)]\nLabels3 = np.asarray(Labels3).reshape(2,2)\nfig,[ax1,ax2] = plt.subplots(nrows=1,ncols=2,figsize=(10,5),constrained_layout = True)\nsns.heatmap(cm1, annot=Labels, fmt='', cmap='Reds',ax=ax1)\nax1.set_xlabel('Predicted labels')\nax1.set_ylabel('True labels')\nax1.set_title(\"Dataset1\")\nax1.xaxis.set_ticklabels([target[0], target[1]]); ax1.yaxis.set_ticklabels([target[0], target[1]])\nsns.heatmap(cm3, annot=Labels3, fmt='', cmap='Blues',ax=ax2)\nax2.set_xlabel('Predicted labels')\nax2.set_ylabel('True labels')\nax2.set_title(\"Dataset2\")\nax2.xaxis.set_ticklabels([target[0], target[1]]); ax2.yaxis.set_ticklabels([target[0], target[1]])\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.7, \n                    hspace=0.7)\n#fig.suptitle(\"This Main Title is Nicely Formatted\", fontsize=16)\n#fig.suptitle('VGG16+CNN Results(Confusion Matrix)')\n#plt.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:55:18.513034Z","iopub.execute_input":"2021-12-21T08:55:18.513642Z","iopub.status.idle":"2021-12-21T08:56:21.157634Z","shell.execute_reply.started":"2021-12-21T08:55:18.513610Z","shell.execute_reply":"2021-12-21T08:56:21.156661Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"<h5>Roc Curve</h5>","metadata":{}},{"cell_type":"code","source":"test_labels = training.classes\nresults = np.argmax(vggmodel19.predict(training), axis=1)\ntest_labels2 = validation.classes\nresults2 = np.argmax(vggmodel19.predict(validation), axis=1)\ntest_labels3 = testing.classes\nresults3 = np.argmax(vggmodel19.predict(testing), axis=1)\nfrom scipy import interp\nfrom itertools import cycle\nfrom sklearn.metrics import roc_curve\nlw = 2\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(1):\n    fpr[i], tpr[i], _ = roc_curve(results,test_labels)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\nfor i in range(1):\n    fpr2[i], tpr2[i], _ = roc_curve(results2,test_labels2)\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n    \nfpr3 = dict()\ntpr3 = dict()\nroc_auc3 = dict()\nfor i in range(1):\n    fpr3[i], tpr3[i], _ = roc_curve(results3,test_labels3)\n    roc_auc3[i] = auc(fpr3[i], tpr3[i])\n\ncolors = cycle(['red', 'red'])\nfor i, color in zip(range(1), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='D1:Training (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\ncolors2 = cycle(['blue', 'blue'])\nfor i, color in zip(range(1), colors2):\n    plt.plot(fpr2[i], tpr2[i], color=color, lw=lw,\n             label='D1:Validation (area = {1:0.2f})'\n             ''.format(i, roc_auc2[i]))\ncolors3 = cycle(['orange', 'orange'])\nfor i, color in zip(range(1), colors3):\n    plt.plot(fpr3[i], tpr3[i], color=color, lw=lw,\n             label='D2 (area = {1:0.2f})'\n             ''.format(i, roc_auc3[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve: VGG19')\nplt.legend(bbox_to_anchor=(1.8, 1.0), loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:57:02.062138Z","iopub.execute_input":"2021-12-21T08:57:02.062562Z","iopub.status.idle":"2021-12-21T08:58:01.039450Z","shell.execute_reply.started":"2021-12-21T08:57:02.062489Z","shell.execute_reply":"2021-12-21T08:58:01.038469Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"<h4>Inception V3</h4>","metadata":{}},{"cell_type":"code","source":"def create_model(input_shape,n_classes,optimizer='adam',fine_tune=0):\n    conv_base = InceptionV3(include_top=False,\n                     weights='imagenet', \n                     input_shape=input_shape)\n    if fine_tune > 0:\n        for layer in conv_base.layers[:-fine_tune]:\n            layer.trainable = False\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n    \n    model = Sequential()\n    model.add(conv_base)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(2, activation='softmax'))\n    \n    model.compile(optimizer = 'adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:58:55.310709Z","iopub.execute_input":"2021-12-21T08:58:55.311040Z","iopub.status.idle":"2021-12-21T08:58:55.319767Z","shell.execute_reply.started":"2021-12-21T08:58:55.311006Z","shell.execute_reply":"2021-12-21T08:58:55.318819Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"input_shape=(224,224,3)\noptim_1 = Adam(lr=0.0001)\nn_classes=2\n\nn_steps=training.samples//128\nn_val_steps=validation.samples//128\nn_epochs=10\n\nvggmodel=create_model(input_shape,n_classes,optim_1,fine_tune=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:59:06.125479Z","iopub.execute_input":"2021-12-21T08:59:06.125840Z","iopub.status.idle":"2021-12-21T08:59:10.395797Z","shell.execute_reply.started":"2021-12-21T08:59:06.125767Z","shell.execute_reply":"2021-12-21T08:59:10.394686Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"vggmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T08:59:22.190761Z","iopub.execute_input":"2021-12-21T08:59:22.191141Z","iopub.status.idle":"2021-12-21T08:59:22.225478Z","shell.execute_reply.started":"2021-12-21T08:59:22.191092Z","shell.execute_reply":"2021-12-21T08:59:22.224511Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vgg_checkpoint = ModelCheckpoint(filepath='cnn+Inception(revised2)_new.weights.best.hdf5',\n                                  save_best_only=True,\n                                  verbose=1)\n\n# EarlyStopping\nearly_stop = EarlyStopping(monitor='val_accuracy',\n                           patience=7,\n                           restore_best_weights=True,\n                           mode='max')\nvgg_history = vggmodel.fit(training,\n                           batch_size=BATCH_SIZE,\n                           epochs=n_epochs,\n                           validation_data=(validation),\n                           steps_per_epoch=n_steps,\n                           validation_steps=n_val_steps,\n                           callbacks=[vgg_checkpoint, early_stop],\n                           verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:35:15.476393Z","iopub.execute_input":"2021-12-07T13:35:15.476649Z","iopub.status.idle":"2021-12-07T13:44:20.866683Z","shell.execute_reply.started":"2021-12-07T13:35:15.476619Z","shell.execute_reply":"2021-12-07T13:44:20.865917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnInception(revised2)_new.weights.best.hdf5') # initialize the best trained weights\ntrue_classes = testing.classes\nvgg_preds = vggmodel.predict(testing)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = testing.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Inception Accuracy Dataset2: {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:00:06.208447Z","iopub.execute_input":"2021-12-21T09:00:06.208937Z","iopub.status.idle":"2021-12-21T09:00:23.294571Z","shell.execute_reply.started":"2021-12-21T09:00:06.208901Z","shell.execute_reply":"2021-12-21T09:00:23.293532Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnInception(revised2)_new.weights.best.hdf5') # initialize the best trained weights\ntrue_classes = training.classes\nvgg_preds = vggmodel.predict(training)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = training.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Inception Accuracy Dataset1(Training): {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:01:06.354836Z","iopub.execute_input":"2021-12-21T09:01:06.355109Z","iopub.status.idle":"2021-12-21T09:01:48.266663Z","shell.execute_reply.started":"2021-12-21T09:01:06.355079Z","shell.execute_reply":"2021-12-21T09:01:48.265517Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nvggmodel.load_weights('../input/cnn-model/cnnInception(revised2)_new.weights.best.hdf5') # initialize the best trained weights\ntrue_classes = validation.classes\nvgg_preds = vggmodel.predict(validation)\nvgg_pred_classes = np.argmax(vgg_preds, axis=1)\nclass_indices = validation.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\ntarget= list(i for i in class_indices.values())\nprint(classification_report(true_classes,vgg_pred_classes, target_names=target))\nvgg_acc = accuracy_score(true_classes, vgg_pred_classes)*100\nprint(\"Inception Accuracy Dataset1(Validation): {:.2f} %\".format(vgg_acc))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:02:31.876952Z","iopub.execute_input":"2021-12-21T09:02:31.877271Z","iopub.status.idle":"2021-12-21T09:02:56.205869Z","shell.execute_reply.started":"2021-12-21T09:02:31.877242Z","shell.execute_reply":"2021-12-21T09:02:56.204663Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"<h5>Confusion Matrix</h5>","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\nimport seaborn as sns\ncm = confusion_matrix(training.classes, np.argmax(vggmodel.predict(training), axis=1))\ncm2 = confusion_matrix(validation.classes, np.argmax(vggmodel.predict(validation), axis=1))\ncm1 = cm+cm2\ncm3 = confusion_matrix(testing.classes, np.argmax(vggmodel.predict(testing), axis=1))\ngroup_names = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm1.flatten()]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm1.flatten()/np.sum(cm1)]\nLabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nLabels = np.asarray(Labels).reshape(2,2)\ngroup_names2 = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts2 = [\"{0:0.0f}\".format(value) for value in cm2.flatten()]\ngroup_percentages2 = [\"{0:.2%}\".format(value) for value in cm2.flatten()/np.sum(cm2)]\nLabels2 = [f\"{v11}\\n{v22}\\n{v33}\" for v11, v22, v33 in zip(group_names2,group_counts2,group_percentages2)]\nLabels2 = np.asarray(Labels2).reshape(2,2)\ngroup_names3 = [\"TP\",\"FP\",\"FN\",\"TN\"]\ngroup_counts3 = [\"{0:0.0f}\".format(value) for value in cm3.flatten()]\ngroup_percentages3 = [\"{0:.2%}\".format(value) for value in cm3.flatten()/np.sum(cm3)]\nLabels3 = [f\"{v111}\\n{v222}\\n{v333}\" for v111, v222, v333 in zip(group_names3,group_counts3,group_percentages3)]\nLabels3 = np.asarray(Labels3).reshape(2,2)\nfig,[ax1,ax2] = plt.subplots(nrows=1,ncols=2,figsize=(10,5),constrained_layout = True)\nsns.heatmap(cm1, annot=Labels, fmt='', cmap='Reds',ax=ax1)\nax1.set_xlabel('Predicted labels')\nax1.set_ylabel('True labels')\nax1.set_title(\"Dataset1\")\nax1.xaxis.set_ticklabels([target[0], target[1]]); ax1.yaxis.set_ticklabels([target[0], target[1]])\nsns.heatmap(cm3, annot=Labels3, fmt='', cmap='Blues',ax=ax2)\nax2.set_xlabel('Predicted labels')\nax2.set_ylabel('True labels')\nax2.set_title(\"Dataset2\")\nax2.xaxis.set_ticklabels([target[0], target[1]]); ax2.yaxis.set_ticklabels([target[0], target[1]])\nplt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.7, \n                    hspace=0.7)\n#fig.suptitle(\"This Main Title is Nicely Formatted\", fontsize=16)\n#fig.suptitle('VGG16+CNN Results(Confusion Matrix)')\n#plt.tight_layout()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:03:30.251071Z","iopub.execute_input":"2021-12-21T09:03:30.251398Z","iopub.status.idle":"2021-12-21T09:04:35.549742Z","shell.execute_reply.started":"2021-12-21T09:03:30.251351Z","shell.execute_reply":"2021-12-21T09:04:35.548728Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"<h5>ROC curve</h5>","metadata":{}},{"cell_type":"code","source":"test_labels = training.classes\nresults = np.argmax(vggmodel.predict(training), axis=1)\ntest_labels2 = validation.classes\nresults2 = np.argmax(vggmodel.predict(validation), axis=1)\ntest_labels3 = testing.classes\nresults3 = np.argmax(vggmodel.predict(testing), axis=1)\nfrom scipy import interp\nfrom itertools import cycle\nfrom sklearn.metrics import roc_curve\nlw = 2\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(1):\n    fpr[i], tpr[i], _ = roc_curve(results,test_labels)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\nfor i in range(1):\n    fpr2[i], tpr2[i], _ = roc_curve(results2,test_labels2)\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n    \nfpr3 = dict()\ntpr3 = dict()\nroc_auc3 = dict()\nfor i in range(1):\n    fpr3[i], tpr3[i], _ = roc_curve(results3,test_labels3)\n    roc_auc3[i] = auc(fpr3[i], tpr3[i])\n\ncolors = cycle(['red', 'red'])\nfor i, color in zip(range(1), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='D1:Training (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\ncolors2 = cycle(['blue', 'blue'])\nfor i, color in zip(range(1), colors2):\n    plt.plot(fpr2[i], tpr2[i], color=color, lw=lw,\n             label='D1:Validation (area = {1:0.2f})'\n             ''.format(i, roc_auc2[i]))\ncolors3 = cycle(['orange', 'orange'])\nfor i, color in zip(range(1), colors3):\n    plt.plot(fpr3[i], tpr3[i], color=color, lw=lw,\n             label='D2 (area = {1:0.2f})'\n             ''.format(i, roc_auc3[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve: InceptionV3')\nplt.legend(bbox_to_anchor=(1.8, 1.0), loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:04:52.076691Z","iopub.execute_input":"2021-12-21T09:04:52.077050Z","iopub.status.idle":"2021-12-21T09:05:59.129631Z","shell.execute_reply.started":"2021-12-21T09:04:52.077020Z","shell.execute_reply":"2021-12-21T09:05:59.128710Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}